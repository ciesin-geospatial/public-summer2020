{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook performs general cleaning on the facility name column and also removes facility type information from the facility name. The extracted type information is then mapped to one of the facility types in the type dictionary.\n",
    "\n",
    "The output columns include:\n",
    "- CLEAN_NAME: clean facility name after some pre-cleaning\n",
    "- CLEAN_NAME_FINAL: final clean name after removing type information\n",
    "- EXTRACT_TYPE: type information extracted, also the difference between CLEAN_NAME and CLEAN_NAME_FINAL\n",
    "- SUB_TYPE: facility type defined in the type dictonary, obtained by mapping EXTRACT_TYPE to type dictionary\n",
    "- SCORE: match score between EXTRACT_TYPE and SUB_TYPE (scale 0-100), can be used to filter perfect-match results only."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import fiona\n",
    "import os\n",
    "import unidecode\n",
    "from fuzzywuzzy import fuzz\n",
    "from fuzzywuzzy import process\n",
    "from ordered_set import OrderedSet\n",
    "pd.set_option('mode.chained_assignment', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import dataset as df\n",
    "dataDir = r\"C:\\Users\\DUANYUEYUN\\Documents\\ArcGIS\\Projects\\GRID3\\Healthsites\"\n",
    "priority_countries = ['South Sudan', 'Mozambique', 'Namibia', 'Nigeria', 'Zambia',\n",
    "                      'Sierra Leone', 'Ghana',  'Burkina Faso', 'Ethiopia', 'Somalia',\n",
    "                      'Rwanda', 'Kenya', 'Zimbabwe', 'Democratic Republic of the Congo']\n",
    "dfs = []\n",
    "for i in range(len(priority_countries)):\n",
    "    country = priority_countries[i]\n",
    "    filename = country + '-node.shp'\n",
    "    path = os.path.join(dataDir, country, filename)\n",
    "    df = gpd.read_file(path)\n",
    "    df['country'] = country\n",
    "    dfs.append(df)\n",
    "df = pd.concat(dfs, axis=0)\n",
    "df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# get the index, for mapping processed data to original dataset\n",
    "df.reset_index(inplace=True)\n",
    "\n",
    "# import type dictionary as TYPE_DICT\n",
    "dataDir = r\"C:\\Users\\DUANYUEYUN\\Documents\\GRID3\\Health facilities\\Data\\Africa\"\n",
    "TYPE_DICT = pd.read_csv(dataDir + \"//type_dict_augmented_1130.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# INPUT\n",
    "# facility name column\n",
    "FACILITY_NAME = 'name'\n",
    "# country column\n",
    "COUNTRY = 'country'\n",
    "\n",
    "# OUTPUT\n",
    "# output columns\n",
    "CLEAN_NAME = 'clean_name' # clean name after some pre-cleaning\n",
    "CLEAN_NAME_FINAL = 'clean_name_final' # final clean name after removing type information\n",
    "EXTRACT_TYPE = 'type_extract' # type information extracted\n",
    "SUB_TYPE = 'sub_type' # type mapped to the type dictonary\n",
    "SCORE = 'score' # match score between 'type_extract' and 'sub_type'\n",
    "\n",
    "# path to save cleaned results\n",
    "SAVE_PATH = r\"C:\\Users\\DUANYUEYUN\\Documents\\GRID3\\Health facilities\\Data\\Africa\\healthsites_cleaned_1202.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: the country column in the dataset must match that in the type dictionary, ignoring cases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check if there's any country that does not exist in type dictionary\n",
    "for c in df[COUNTRY]:\n",
    "    if c not in TYPE_DICT['Country'].unique():\n",
    "        print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Country names in the type dictionary:\n",
      "['Angola' 'Benin' 'Botswana' 'Burkina Faso' 'Burundi' 'Cameroon'\n",
      " 'Cape Verde' 'Central African Republic' 'Chad' 'Comoros' 'Congo'\n",
      " \"Cote d'Ivoire\" 'Democratic Republic of the Congo' 'Djibouti'\n",
      " 'Equatorial Guinea' 'Eritrea' 'Ethiopia' 'Gabon' 'Gambia' 'Ghana'\n",
      " 'Guinea' 'Guinea Bissau' 'Kenya' 'Lesotho' 'Liberia' 'Madagascar'\n",
      " 'Malawi' 'Mali' 'Mauritania' 'Mauritius' 'Mozambique' 'Namibia' 'Niger'\n",
      " 'Nigeria' 'Rwanda' 'Sao Tome and Principe' 'Senegal' 'Seychelles'\n",
      " 'Sierra Leone' 'Somalia' 'South Africa' 'South Sudan' 'Sudan' 'Tanzania'\n",
      " 'Togo' 'Uganda' 'Zambia' 'Zanzibar' 'Zimbabwe' 'eSwatini']\n"
     ]
    }
   ],
   "source": [
    "print(\"Country names in the type dictionary:\")\n",
    "print(TYPE_DICT['Country'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `clean_name`\n",
    "\n",
    "Pre-cleaning on facility name:\n",
    "\n",
    "- remove punctuations, change '&' to 'and'\n",
    "- correct spelling of common words\n",
    "- replace double whitespaces with one and strip extra whitespaces\n",
    "- remove accent marks\n",
    "\n",
    "Note: NA values in facility name column is replaced with empty string '' first and then converted back to NA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preclean(df, facility_name = FACILITY_NAME, clean_name = CLEAN_NAME):\n",
    "    # replace NAs with empty string ''\n",
    "    df[facility_name] = df[facility_name].fillna('')\n",
    "    \n",
    "    df[clean_name] = df[facility_name].str.strip()\\\n",
    "            .str.replace(\"  \", \" \")\\\n",
    "            .str.replace('.', ' ')\\\n",
    "            .str.replace(':', ' ')\\\n",
    "            .str.replace(\"'\", ' ')\\\n",
    "            .str.replace('\"', ' ')\\\n",
    "            .str.replace('[-_,/\\(\\)]', ' ')\\\n",
    "            .str.replace('&', ' and ')\\\n",
    "            .str.strip()\\\n",
    "            .str.replace('center', 'centre', case=False)\\\n",
    "            .str.replace('Clinique', 'Clinic', case=False)\\\n",
    "            .str.replace('Polyclinique', 'Polyclinic', case=False)\\\n",
    "            .str.replace('Geral', 'General', case=False)\\\n",
    "            .str.replace('Dispensaire', 'Dispensary', case=False)\\\n",
    "            .str.replace('HÃ´pital', 'Hospital', case=False)\\\n",
    "            .str.replace('Hopital', 'Hospital', case=False)\\\n",
    "            .str.replace('Hospitais', 'Hospital', case=False)\\\n",
    "            .str.replace(' Hosp | hosp$', ' Hospital ', case=False)\\\n",
    "            .str.replace(\"Urbain\", \"Urban\", case=False)\\\n",
    "            .str.replace(\"Distrital\", \"District\", case=False)\\\n",
    "            .str.replace(\"  \", \" \")\\\n",
    "            .str.strip()\n",
    "    \n",
    "    # replace NAs in clean_name with empty string ''\n",
    "    df[clean_name] = df[clean_name].fillna('')\n",
    "    \n",
    "    # change emptry string in facility_name back to NA\n",
    "    df[facility_name] = df[facility_name].replace('', np.nan)\n",
    "\n",
    "    # remove accent marks\n",
    "    df[clean_name] = [unidecode.unidecode(n) for n in df[clean_name]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `clean_name_final`\n",
    "\n",
    "Use facility type and abbreviations in the type dictionary as keywords and remove type information from `clean_name` to create the `clean_name_final` column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_type_info(df, type_dict, clean_name, clean_name_final, country):\n",
    "    # remove whitespace between abbreviations of length 2 or 3\n",
    "    # e.g. change C S to CS\n",
    "    \n",
    "    # obtain abbreviations of length 2 or 3\n",
    "    tmp = type_dict[type_dict['Abbreviation'].str.len()<=3]['Abbreviation'].unique()\n",
    "    # sort by decreasing length\n",
    "    tmp = sorted(tmp, key=len, reverse=True)\n",
    "    # change it to the pattern '^c s ' or ' c s$'\n",
    "    tmp_dict = {}\n",
    "    for t in tmp:\n",
    "        tmp_dict[t] = ['^'+' '.join(list(t))+' ', ' '+' '.join(list(t))+'$']\n",
    "    # replace the pattern with 'cs'\n",
    "    for t in tmp:\n",
    "        pats = tmp_dict[t]\n",
    "        df[clean_name] = df[clean_name].str.replace(pats[0], t+' ',case=False)\\\n",
    "        .str.replace(pats[1], ' '+t, case=False)\n",
    "        \n",
    "    # remove type information\n",
    "    df_grouped = df.groupby(country)\n",
    "    res = pd.DataFrame()\n",
    "\n",
    "    for group_name, df_group in df_grouped:\n",
    "        # obtain the type dictionary for that country\n",
    "        tmp = type_dict[type_dict['Country'].str.upper()==group_name.upper()]\n",
    "\n",
    "        # facility types for that country\n",
    "        types = list(tmp['Type'])\n",
    "        type_keywords = set()\n",
    "        for t in types:\n",
    "            # add the full facility type \n",
    "            t = t.title()\n",
    "            type_keywords.add(t)                 \n",
    "\n",
    "            # add individual words as well\n",
    "            t = t.replace('/', ' ')\n",
    "            words = t.split(' ')\n",
    "            # skip words that have punctuation / numbers and have length <= 3 (e.g. de, (major))\n",
    "            words = [w for w in words if w.isalpha() and len(w)>3]\n",
    "            for w in words:\n",
    "                type_keywords.add(w)\n",
    "\n",
    "        # obtain the list of type keywords and sort in descending length\n",
    "        type_keywords = list(type_keywords)\n",
    "        type_keywords = sorted(type_keywords, key=lambda s: -len(s))\n",
    "\n",
    "        # abbreviations for that country\n",
    "        abbrevs = set(tmp['Abbreviation'])\n",
    "\n",
    "        abb_keywords = []\n",
    "        for abbrev in abbrevs:\n",
    "            # e.g. for CS, 4 patterns are considered: '^CS ', ' CS ', ' CS$', '^CS$'\n",
    "            abbrev = abbrev.title()\n",
    "            abb_keywords.extend(['^'+abbrev+'\\s', '\\s'+abbrev+'\\s', '\\s'+abbrev+'$',\n",
    "                                '^'+abbrev+'$'])\n",
    "\n",
    "        # obtain the list of abbreviation keywords and sort in descending length\n",
    "        abb_keywords = sorted(abb_keywords, key=lambda s: -len(s))  \n",
    "\n",
    "        # some country-specific adjustments\n",
    "        if group_name.upper() == 'UGANDA':\n",
    "            df_group[clean_name] = df_group[clean_name].str.replace(\"HC II$\", \"HCII\", case=False)\\\n",
    "            .str.replace(\"HC III$\", \"HCIII\", case=False)\\\n",
    "            .str.replace(\"HC IV$\", \"HCIV\", case=False)\n",
    "\n",
    "        if group_name.upper() == 'MALAWI':\n",
    "            df_group[clean_name] = df_group[clean_name].str.replace(\" DHO$\", \" DH\", case=False)\n",
    "\n",
    "        if group_name.upper() == \"ERITREA\":\n",
    "            df_group[clean_name] = df_group[clean_name].str.replace(\" HO$\", \" HOSP\", case=False)\n",
    "\n",
    "        if group_name.upper() == 'MADAGASCAR':\n",
    "            df_group[clean_name] = df_group[clean_name].str.replace(\"csb 1\", \" csb1\", case=False)\n",
    "            df_group[clean_name] = df_group[clean_name].str.replace(\"csb 2\", \" csb2\", case=False)\n",
    "\n",
    "        # handle situations when type is 'Hospital District' in the type dictionary \n",
    "        # but name column has 'District Hospital' in ISS data\n",
    "        type_len_2 = [t for t in type_keywords if len(t.split())==2]\n",
    "        for t in type_len_2:\n",
    "            df_group[clean_name] = df_group[clean_name].str.title()\\\n",
    "            .str.replace(' '.join(t.split()[::-1]), t, case=False)\n",
    "\n",
    "        # remove type information using keywords generated above\n",
    "        # remove meaningless connecting words like de, do, da, du\n",
    "        df_group[clean_name_final] = df_group[clean_name].str.title()\\\n",
    "            .str.replace('|'.join(type_keywords), '')\\\n",
    "            .str.replace('|'.join(abb_keywords), ' ')\\\n",
    "            .str.strip()\\\n",
    "            .str.replace('^de | de | de$|^de$|^do | do | do$|^do$|^da | da | da$|^da$|^du | du | du$|^du$', \n",
    "                         ' ', case=False)\\\n",
    "            .str.replace(\"  \", \" \")\\\n",
    "            .str.strip()\\\n",
    "            .str.title()\n",
    "        res = pd.concat([res, df_group])\n",
    "    return res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `extract_type`\n",
    "\n",
    "Extract facility type information by removing `clean_name_final` from `clean_name`.\n",
    "\n",
    "Note: empty string '' in `clean_name_final` from `clean_name` are converted back to NA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_type(df, clean_name, clean_name_final, extract_type):\n",
    "    extract_types = []\n",
    "\n",
    "    for idx, row in df.iterrows():\n",
    "        name = row[clean_name].upper()\n",
    "        name_final = row[clean_name_final].upper()\n",
    "\n",
    "        # if clean_name_final is exactly the same as clean_name,\n",
    "        # this indicates no type information can be extracted, thus append NA\n",
    "        if name.upper() == name_final.upper():\n",
    "            extract_types.append(np.nan)\n",
    "\n",
    "        else:\n",
    "            name = OrderedSet(name.split())\n",
    "            name_final = OrderedSet(name_final.split())\n",
    "            # find the difference between two names\n",
    "            diff = ' '.join(list(name.difference(name_final)))\n",
    "            extract_types.append(diff.strip())\n",
    "\n",
    "    # remove de, do, da, du at start or end of extract_type\n",
    "    # replace empty string with NA\n",
    "    df[extract_type] = extract_types\n",
    "    df[extract_type] = df[extract_type].str.strip()\\\n",
    "        .str.replace(\"  \", \" \")\\\n",
    "        .str.replace('^de |^do |^da |^du | du$| de$| do$| da$|^de$|^do$|^da$|^du$', '', case=False)\\\n",
    "        .str.replace('^de |^do |^da |^du | du$| de$| do$| da$|^de$|^do$|^da$|^du$', '', case=False)\\\n",
    "        .str.strip()\\\n",
    "        .str.title()\\\n",
    "        .replace('',np.nan)\n",
    "    # replace empty string with NA\n",
    "    df[clean_name].replace('', np.nan, inplace=True)\n",
    "    df[clean_name_final].replace('', np.nan, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `sub_type`\n",
    "\n",
    "Use `extract_type` to map the type information extracted from the name column to one of the types in the type dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_type(df, country, extract_type, sub_type, score, type_dict):\n",
    "    df_grouped = df.groupby(country)\n",
    "    res = pd.DataFrame()\n",
    "    for country_name in df[country].unique():\n",
    "        df_group = df[df[country]==country_name]\n",
    "        # obtain facility types and abbreviations for that country\n",
    "        tmp = type_dict[type_dict['Country'].str.upper()==country_name.upper()]\n",
    "        types, abbrevs = tmp['Type'], tmp['Abbreviation']\n",
    "        sub_types = []\n",
    "        scores = []\n",
    "\n",
    "        for idx, row in df_group.iterrows():\n",
    "            # if extract_type is NA, just append NA\n",
    "            if not isinstance(row[extract_type],str):\n",
    "                sub_types.append(np.nan)\n",
    "                scores.append(np.nan)\n",
    "\n",
    "            # find best match\n",
    "            else:\n",
    "                match, match_score = process.extractOne(row[extract_type], list(types)+list(abbrevs), \n",
    "                                               scorer = fuzz.ratio)\n",
    "                scores.append(match_score)\n",
    "                # if best match is abbreviation, map it to the corresponding type\n",
    "                if match in list(abbrevs):\n",
    "                    match_type = tmp[tmp['Abbreviation']==match]['Type'].iloc[0]\n",
    "                    sub_types.append(match_type)\n",
    "                else:\n",
    "                    sub_types.append(match) \n",
    "        df_group[sub_type] = sub_types\n",
    "        df_group[score] = scores\n",
    "        res = pd.concat([res, df_group])\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def export_results(df, save_path):\n",
    "    # export results\n",
    "    # index_original could be used to map results to original dataset\n",
    "    df.rename(columns={'index':'index_original'}, inplace=True)\n",
    "    df.to_csv(save_path, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Apply cleaning functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pre-cleaning\n",
    "preclean(df, facility_name = FACILITY_NAME, clean_name = CLEAN_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove type information\n",
    "res = remove_type_info(df, type_dict=TYPE_DICT, clean_name=CLEAN_NAME, \n",
    "                       clean_name_final=CLEAN_NAME_FINAL, country=COUNTRY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# obtain facility type extracted\n",
    "extract_type(df=res, clean_name=CLEAN_NAME, \n",
    "             clean_name_final=CLEAN_NAME_FINAL, extract_type=EXTRACT_TYPE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage of NA in extract type column: 41.5\n",
      "Number of NA values in extract type column: 3071\n"
     ]
    }
   ],
   "source": [
    "print(\"Percentage of NA in extract type column:\",\n",
    "     round(res[EXTRACT_TYPE].isna().sum()/res.shape[0]*100,1))\n",
    "print(\"Number of NA values in extract type column:\", res[pd.isna(res[EXTRACT_TYPE])].shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# map facility type extracted to type in type dictionary\n",
    "res = map_type(df=res, country = COUNTRY, extract_type=EXTRACT_TYPE, \n",
    "               sub_type=SUB_TYPE, score=SCORE, type_dict=TYPE_DICT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary statistics of match score:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "count    4329.000000\n",
       "mean       95.684685\n",
       "std        11.394158\n",
       "min        32.000000\n",
       "25%       100.000000\n",
       "50%       100.000000\n",
       "75%       100.000000\n",
       "max       100.000000\n",
       "Name: score, dtype: float64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Summary statistics of match score:\")\n",
    "res[SCORE].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>country</th>\n",
       "      <th>name</th>\n",
       "      <th>clean_name</th>\n",
       "      <th>clean_name_final</th>\n",
       "      <th>type_extract</th>\n",
       "      <th>sub_type</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>692</th>\n",
       "      <td>Mozambique</td>\n",
       "      <td>Centro de Saude de Furancungo</td>\n",
       "      <td>Centro De Saude De Furancungo</td>\n",
       "      <td>Furancungo</td>\n",
       "      <td>Centro De Saude</td>\n",
       "      <td>Centro de Saude</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>290</th>\n",
       "      <td>Mozambique</td>\n",
       "      <td>Centro de Saude de Chinhambuzi</td>\n",
       "      <td>Centro De Saude De Chinhambuzi</td>\n",
       "      <td>Chinhambuzi</td>\n",
       "      <td>Centro De Saude</td>\n",
       "      <td>Centro de Saude</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4743</th>\n",
       "      <td>Kenya</td>\n",
       "      <td>Kutulo Health Center</td>\n",
       "      <td>Kutulo Health Centre</td>\n",
       "      <td>Kutulo</td>\n",
       "      <td>Health Centre</td>\n",
       "      <td>Health Centre</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3901</th>\n",
       "      <td>Ethiopia</td>\n",
       "      <td>Aba Health Center</td>\n",
       "      <td>Aba Health Centre</td>\n",
       "      <td>Aba</td>\n",
       "      <td>Health Centre</td>\n",
       "      <td>Health Centre</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6903</th>\n",
       "      <td>Democratic Republic of the Congo</td>\n",
       "      <td>PS HEWA BORA</td>\n",
       "      <td>Ps Hewa Bora</td>\n",
       "      <td>Hewa Bora</td>\n",
       "      <td>Ps</td>\n",
       "      <td>Poste de Sante</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               country                            name  \\\n",
       "692                         Mozambique   Centro de Saude de Furancungo   \n",
       "290                         Mozambique  Centro de Saude de Chinhambuzi   \n",
       "4743                             Kenya            Kutulo Health Center   \n",
       "3901                          Ethiopia               Aba Health Center   \n",
       "6903  Democratic Republic of the Congo                    PS HEWA BORA   \n",
       "\n",
       "                          clean_name clean_name_final     type_extract  \\\n",
       "692    Centro De Saude De Furancungo       Furancungo  Centro De Saude   \n",
       "290   Centro De Saude De Chinhambuzi      Chinhambuzi  Centro De Saude   \n",
       "4743            Kutulo Health Centre           Kutulo    Health Centre   \n",
       "3901               Aba Health Centre              Aba    Health Centre   \n",
       "6903                    Ps Hewa Bora        Hewa Bora               Ps   \n",
       "\n",
       "             sub_type  score  \n",
       "692   Centro de Saude  100.0  \n",
       "290   Centro de Saude  100.0  \n",
       "4743    Health Centre  100.0  \n",
       "3901    Health Centre  100.0  \n",
       "6903   Poste de Sante  100.0  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# randomly sample rows to examine results\n",
    "# where type information is extracted\n",
    "cols = [COUNTRY, FACILITY_NAME, CLEAN_NAME, CLEAN_NAME_FINAL, EXTRACT_TYPE,\n",
    "       SUB_TYPE, SCORE]\n",
    "res[~pd.isna(res[EXTRACT_TYPE])][cols].sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>country</th>\n",
       "      <th>name</th>\n",
       "      <th>clean_name</th>\n",
       "      <th>clean_name_final</th>\n",
       "      <th>type_extract</th>\n",
       "      <th>sub_type</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4924</th>\n",
       "      <td>Kenya</td>\n",
       "      <td>Neem Pharmacy</td>\n",
       "      <td>Neem Pharmacy</td>\n",
       "      <td>Neem Pharmacy</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3002</th>\n",
       "      <td>Ghana</td>\n",
       "      <td>Haskay Pharmacy</td>\n",
       "      <td>Haskay Pharmacy</td>\n",
       "      <td>Haskay Pharmacy</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1877</th>\n",
       "      <td>Nigeria</td>\n",
       "      <td>Rauda Street</td>\n",
       "      <td>Rauda Street</td>\n",
       "      <td>Rauda Street</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4173</th>\n",
       "      <td>Ethiopia</td>\n",
       "      <td>Kebron Pharmacy</td>\n",
       "      <td>Kebron Pharmacy</td>\n",
       "      <td>Kebron Pharmacy</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6084</th>\n",
       "      <td>Democratic Republic of the Congo</td>\n",
       "      <td>La Grace</td>\n",
       "      <td>La Grace</td>\n",
       "      <td>La Grace</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               country             name       clean_name  \\\n",
       "4924                             Kenya    Neem Pharmacy    Neem Pharmacy   \n",
       "3002                             Ghana  Haskay Pharmacy  Haskay Pharmacy   \n",
       "1877                           Nigeria     Rauda Street     Rauda Street   \n",
       "4173                          Ethiopia  Kebron Pharmacy  Kebron Pharmacy   \n",
       "6084  Democratic Republic of the Congo         La Grace         La Grace   \n",
       "\n",
       "     clean_name_final type_extract sub_type  score  \n",
       "4924    Neem Pharmacy          NaN      NaN    NaN  \n",
       "3002  Haskay Pharmacy          NaN      NaN    NaN  \n",
       "1877     Rauda Street          NaN      NaN    NaN  \n",
       "4173  Kebron Pharmacy          NaN      NaN    NaN  \n",
       "6084         La Grace          NaN      NaN    NaN  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# randomly sample rows to examine results\n",
    "# where no type information is extracted\n",
    "res[pd.isna(res[EXTRACT_TYPE])][cols].sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export results\n",
    "export_results(res, save_path=SAVE_PATH)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
