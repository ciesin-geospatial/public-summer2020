{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import fiona\n",
    "import geopandas as gpd\n",
    "import os\n",
    "from fuzzywuzzy import fuzz\n",
    "from fuzzywuzzy import process\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.mode.chained_assignment = None\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combine data sources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data import\n",
    "dataDir = r\"C:\\Users\\DUANYUEYUN\\Documents\\GRID3\\Health facilities\\Data\\DRC\\\\Cleaned\\\\Single source\\\\2nd round\"\n",
    "acasus_dropped2 = pd.read_csv(dataDir + \"\\\\acasus_dropped2_0921.csv\")\n",
    "who_dropped2 = pd.read_csv(dataDir + \"\\\\who_dropped2_0921.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop unnecessary columns\n",
    "acasus_dropped2.drop(columns=['freq_count',\n",
    "       'match_name', 'n_subclusters', 'match_score', 'match_type', 'name_seq',\n",
    "       'type_seq', 'clusterID', 'IN_FID_y',\n",
    "       'IN_FID_y', 'FEAT_SEQ_y', 'eval2'],\n",
    "                    inplace=True)\n",
    "who_dropped2.drop(columns=['freq_count', 'match_name', 'n_subclusters',\n",
    "       'match_score', 'match_type', 'name_seq', 'type_seq', 'clusterID',\n",
    "        'IN_FID_y',\n",
    "       'FEAT_SEQ_y', 'eval2'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create source column\n",
    "acasus_dropped2['source'] = 'acasus'\n",
    "who_dropped2['source'] = 'who'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rename some columns\n",
    "acasus_dropped2.rename({'date':'date_dt'}, axis=1, inplace=True)\n",
    "who_dropped2.rename({'province':'province1'}, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine datasets\n",
    "df = pd.concat([acasus_dropped2, who_dropped2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10854, 54)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "acasus    7965\n",
       "who       2889\n",
       "Name: source, dtype: int64"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['source'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataDir = r\"C:\\Users\\DUANYUEYUN\\Documents\\GRID3\\Health facilities\\Data\\DRC\\\\Cleaned\"\n",
    "df.to_csv(dataDir + \"\\\\combined_list_0927.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`IN_FID` and `IN_FID_x` can be used to match back to original datasets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add feature sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataDir = r\"C:\\Users\\DUANYUEYUN\\Documents\\GRID3\\Health facilities\\Data\\DRC\\\\Cleaned\"\n",
    "combined_list = pd.read_csv(dataDir + \"\\\\combined_list_0927.csv\")\n",
    "dataDir2 = r\"C:\\Users\\DUANYUEYUN\\Documents\\ArcGIS\\Projects\\Fuzzy Match Testing\"\n",
    "seq2 = gpd.read_file(dataDir2+\"\\\\Fuzzy Match Testing.gdb\", driver='FileGDB', \n",
    "                       layer= 'combined_list_0922_FindIdent')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# minus 1 from IN_FID in who_seq to match index of the original dataset\n",
    "seq2['IN_FID'] = seq2['IN_FID']-1\n",
    "# drop duplicates in IN_FID since some points are assigned to more than 1 cluster\n",
    "seq2 = seq2.sort_values(by=['IN_FID', 'FEAT_SEQ'])\\\n",
    ".drop_duplicates(subset='IN_FID', keep='first')\n",
    "\n",
    "combined_list2 = combined_list.merge(seq2.drop(columns=['geometry']), \n",
    "                           left_index=True, right_on='IN_FID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of data points: 10854\n",
      "Number of clusters: 7854\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of data points:\", combined_list.shape[0])\n",
    "print(\"Number of clusters:\", seq2['FEAT_SEQ'].nunique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Match facility names within clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def match_names(df, name='face_name1', clean_name='face_name2_corr',\n",
    "               cluster='FEAT_SEQ', source='source', \n",
    "                     simple_score=80, simple_score_min=50, \n",
    "                     partial_score=80):\n",
    "\n",
    "    # strip whitespaces to remove empty strings like ' '\n",
    "    df[name]=df[name].str.strip()\n",
    "    # replace empty string with NA\n",
    "    df[name].replace('',np.nan,inplace=True)\n",
    "    df[name].replace('NA',np.nan,inplace=True)\n",
    "    \n",
    "    # if the cleaned short name is NA, just use original facility name instead\n",
    "    names = []\n",
    "    for idx, row in df.iterrows():\n",
    "        if isinstance(row[clean_name], str):\n",
    "            names.append(row[clean_name])\n",
    "        else:\n",
    "            names.append(row[name])\n",
    "    df[clean_name] = names \n",
    "    \n",
    "    # drop NA in short name\n",
    "    print(\"Number of NA values in name column:\", df[clean_name].isna().sum())\n",
    "    df.dropna(subset=[clean_name], inplace=True)\n",
    "\n",
    "    # sort values based on feature sequence and short name\n",
    "    df.sort_values(by=[cluster, clean_name, source], inplace=True)\n",
    "    # group by feature sequence\n",
    "    df_grouped = df.groupby(cluster)\n",
    "\n",
    "    # store the matched name\n",
    "    match_names = []\n",
    "    # store count of subclusters\n",
    "    sub_counts = []\n",
    "    # store score of matching\n",
    "    match_scores = []\n",
    "    # store types of matching\n",
    "    match_types = []\n",
    "\n",
    "    for group_name, df_group in df_grouped:\n",
    "        # obtain list of names\n",
    "        names = df_group[clean_name].to_list()\n",
    "        \n",
    "        # use the first name as the potential candidates for finding a match\n",
    "        match_candidates = [names[0]]\n",
    "        match_names.append(names[0])\n",
    "        match_scores.append(np.nan)\n",
    "        match_types.append('Self')\n",
    "\n",
    "        for i in range(1, len(names)):\n",
    "\n",
    "            name = names[i]\n",
    "\n",
    "            # use match candidates to find best match and compute match score\n",
    "            match_name1, score1 = process.extractOne(name, match_candidates, scorer = fuzz.ratio)\n",
    "            match_name2, score2 = process.extractOne(name, match_candidates, scorer = fuzz.partial_ratio)\n",
    "\n",
    "            # score based on simple ratio\n",
    "            # or for very short strings, a single letter difference will result in low score\n",
    "            # consider two short strings as a match if there's only 1 letter difference\n",
    "            if score1>=simple_score or (1-score1/100) * len(name) <= 1:\n",
    "                # append match name and score\n",
    "                match_names.append(match_name1)\n",
    "                match_scores.append(score1)\n",
    "                match_types.append('Simple match')\n",
    "\n",
    "            # if simple ratio not that high, check partial ratio\n",
    "            elif score1>=simple_score_min and score2>=partial_score:\n",
    "                # append match name and score\n",
    "                match_names.append(match_name2)\n",
    "                match_scores.append(score2)\n",
    "                match_types.append('Partial match')\n",
    "\n",
    "            # the match score based on simple ratio is lower than the minimum required\n",
    "            # just match the name to itself and add it to match candidates\n",
    "            else:\n",
    "                match_candidates.append(name)\n",
    "                match_names.append(name)\n",
    "                match_scores.append(np.nan)\n",
    "                match_types.append('Self')\n",
    "\n",
    "        for i in range(len(names)):\n",
    "            sub_counts.append(len(match_candidates))\n",
    "    \n",
    "    df['match_name'] = match_names\n",
    "    df['n_subclusters'] = sub_counts\n",
    "    df['match_score'] = match_scores\n",
    "    df['match_type'] = match_types\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of NA values in name column: 1\n"
     ]
    }
   ],
   "source": [
    "list_matched = match_names(combined_list2, name='face_name1', clean_name='face_name2_corr',\n",
    "               cluster='FEAT_SEQ', source='source')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "#list_matched[list_matched['FEAT_SEQ'].isin([9,10,11])]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate if points in one cluster are from both sources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_val(df, cluster='FEAT_SEQ', match_name='match_name',\n",
    "              source='source', n_source=2, val_col='val'):\n",
    "    \"\"\"Cross validate points within a cluster.\n",
    "    If they are from both sources => 1, otherwise the value is 0.\n",
    "    \n",
    "    val_col: column name for cross validation.\"\"\"\n",
    "    \n",
    "    df_grouped = df.groupby([cluster, match_name])\n",
    "    val = []\n",
    "    for name, df_group in df_grouped:\n",
    "        # if points are from just 1 source, append 0 \n",
    "        if df_group[source].nunique()==1:\n",
    "            for idx, row in df_group.iterrows():\n",
    "                val.append(0)\n",
    "        # if points are from both sources, append 1\n",
    "        elif df_group[source].nunique()==n_source:\n",
    "            for idx, row in df_group.iterrows():\n",
    "                val.append(1)  \n",
    "    df[val_col]=val\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_val = cross_val(list_matched)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of facilities match by both sources: 1574\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of facilities match by both sources:\", list_val[list_val['val']==1]['FEAT_SEQ'].nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "#list_val[list_val['FEAT_SEQ'].isin([9,10,11])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "matched_points = list_val[list_val['val']==1]\n",
    "matched_points.to_csv(dataDir+'\\\\matched_points_0927.csv',\n",
    "                     index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Consider facility type as well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Centre de Sante', 'Centre de Sante de Reference',\n",
       "       'Poste de Sante', 'Centre Hospitalier', nan,\n",
       "       'Hopital General de Reference', 'Polyclinique',\n",
       "       'Centre Hopitalier', 'Dispensaire', 'Clinique',\n",
       "       'Clinique Universitaires', 'Hopital', 'Centre Medical',\n",
       "       'Centre de Sante Reference', 'Maternite',\n",
       "       'Centre Hopital General de Reference',\n",
       "       'Centre Medical Evangelique', 'Hopital Provincial de Reference',\n",
       "       'Hopital Secondaire', 'Hopital Militaire de Reference'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# examine unique facility types\n",
    "acasus_dropped2['type_corr'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([nan, 'Centre de Sante', 'Hopital General de Reference',\n",
       "       'Poste de Sante', 'Clinique', 'Dispensaire', 'Hopital',\n",
       "       'Centre de Sante de Reference', 'Polyclinique',\n",
       "       'Centre Hopitalier', 'Clinique Universitaires',\n",
       "       'Centre Hospitalier', 'Centre Medical', 'Maternite',\n",
       "       'Centre Pediatrique', 'Hopital Secondaire', 'Pharmacy',\n",
       "       'Cliniques Universitaires', 'Hopital Militaire'], dtype=object)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "who_dropped2['type_corr'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# simple facility mapping\n",
    "type_dict = {\"Centre Hospitalier\":\"Centre Hopitalier\", \n",
    "             \"Cliniques Universitaires\":\"Clinique Universitaires\",\n",
    "            \"Centre de Sante Reference\":\"Centre de Sante de Reference\"}\n",
    "combined_list2['type_corr2'] = [type_dict[type_corr] if type_corr in type_dict.keys() \n",
    "                                else type_corr for type_corr in combined_list2['type_corr']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_val2(df, cluster='FEAT_SEQ', match_name='match_name',\n",
    "               fac_type = 'type_corr2',\n",
    "              source='source', n_source=2, val_col='val'):\n",
    "    df[fac_type] = df[fac_type].fillna('')\n",
    "    # consider facility type as well\n",
    "    df_grouped = df.groupby([cluster, match_name, fac_type])\n",
    "    val = []\n",
    "    for name, df_group in df_grouped:\n",
    "        if df_group[source].nunique()==1:\n",
    "            for idx, row in df_group.iterrows():\n",
    "                val.append(0)\n",
    "        \n",
    "        elif df_group[source].nunique()==n_source:\n",
    "            for idx, row in df_group.iterrows():\n",
    "                val.append(1)  \n",
    "    df[val_col]=val\n",
    "    df[fac_type] = df[fac_type].replace('', np.nan)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_val2 = cross_val2(list_matched)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of facilities match by both sources: 1370\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of facilities match by both sources:\", list_val2[list_val2['val']==1]['FEAT_SEQ'].nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "matched_points2 = list_val2[list_val2['val']==1]\n",
    "matched_points2.to_csv(dataDir+'\\\\matched_points2_0927.csv',\n",
    "                     index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "#matched_points[~matched_points['IN_FID_y'].isin(matched_points2['IN_FID_y'])].head(6)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
